{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c588e83d",
   "metadata": {},
   "source": [
    "# Machine Learning for River Prediction (Exercise Notebook)\n",
    "\n",
    "This notebook will guide you step-by-step through building and evaluating machine learning models to predict outcomes related to river data. Follow the instructions, complete the tasks, and fill in the code where indicated.\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "In this exercise, you will:\n",
    "- Obtain and merge datasets\n",
    "- Create new features from the data\n",
    "- Build, train, and evaluate different machine learning models\n",
    "- Interpret and visualize the results\n",
    "\n",
    "**Learning Objectives**:\n",
    "- Understand how to work with data in a machine learning context.\n",
    "- Learn how to combine and preprocess datasets.\n",
    "- Train models such as Linear Regression, Decision Tree, and XGBoost.\n",
    "- Compare model performances and interpret feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa19ab1",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition and Preparation\n",
    "\n",
    "### Task 1: Load the data\n",
    "Use pandas to load the training and testing datasets provided. Each dataset represents a different time split of the same data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5555ace-1cf2-4de7-a21a-808e5ce9a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the train and test datasets\n",
    "df_train = pd.read_csv('data/train.csv', index_col=0)\n",
    "df_test = pd.read_csv('data/test.csv', index_col=0)\n",
    "\n",
    "# Tag each dataset to distinguish between them\n",
    "df_train['tt'] = 'train'\n",
    "df_test['tt'] = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c427c",
   "metadata": {},
   "source": [
    "### Task 2: Merge the datasets\n",
    "Combine the training and test sets into one dataframe so that we can perform feature engineering on the entire dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783562df-79ff-4474-bc5b-6727376d90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the train and test datasets\n",
    "df = pd.concat([df_train, df_test])\n",
    "\n",
    "# Display the first few rows to confirm the merge\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d70bdee",
   "metadata": {},
   "source": [
    "## 3. Feature Creation\n",
    "\n",
    "### Task 3: Create new features\n",
    "We will now create new features from the existing data that could improve the performance of our machine learning models.\n",
    "\n",
    "**Guidelines for feature creation**:\n",
    "- **Datetime Features**: Extract useful features from the timestamp, such as year, month, day, and hour.\n",
    "- **Interactions**: Create new features by interacting existing ones (e.g., multiplication or ratios).\n",
    "- **Aggregations**: If you have categories, compute averages, sums, or other statistics per category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d362f59-0690-418b-864b-4a2f46a527ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Creating datetime-based features\n",
    "df['year'] = pd.to_datetime(df['timestamp']).dt.year\n",
    "df['month'] = pd.to_datetime(df['timestamp']).dt.month\n",
    "df['day'] = pd.to_datetime(df['timestamp']).dt.day\n",
    "\n",
    "# Create additional features as needed\n",
    "# Example: interaction features\n",
    "df['feature_interaction'] = df['feature1'] * df['feature2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea7eb8d",
   "metadata": {},
   "source": [
    "### Task 4: Handle missing values\n",
    "Check for missing values and decide on a strategy to handle them (e.g., imputation, removal).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76bbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# You can either fill missing values or drop rows/columns\n",
    "# Example: filling missing values with the mean\n",
    "df.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00124e0d",
   "metadata": {},
   "source": [
    "## 4. Data Splitting and Preprocessing\n",
    "\n",
    "### Task 5: Split the data back into train and test sets\n",
    "Now that weâ€™ve processed the data, let's split it back into training and testing sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9754f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the combined dataset back into train and test sets\n",
    "df_train = df[df['tt'] == 'train'].drop(columns=['tt'])\n",
    "df_test = df[df['tt'] == 'test'].drop(columns=['tt'])\n",
    "\n",
    "# Define X and y for both train and test sets\n",
    "X_train = df_train.drop(columns=['target_column'])  # Replace 'target_column' with your target variable\n",
    "y_train = df_train['target_column']  # Replace 'target_column' with your target variable\n",
    "\n",
    "X_test = df_test.drop(columns=['target_column'])\n",
    "y_test = df_test['target_column']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e13075",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation\n",
    "\n",
    "### Task 6: Train a Linear Regression Model\n",
    "Use `LinearRegression` from sklearn to fit the model and evaluate its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9cc358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03906431",
   "metadata": {},
   "source": [
    "### Task 7: Train a Decision Tree Model\n",
    "Repeat the steps to train a Decision Tree model and compare its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e51cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Initialize and train the model\n",
    "tree_model = DecisionTreeRegressor()\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_tree_pred = tree_model.predict(X_test)\n",
    "tree_mse = mean_squared_error(y_test, y_tree_pred)\n",
    "print(f'Decision Tree Mean Squared Error: {tree_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb9a95",
   "metadata": {},
   "source": [
    "## 6. Feature Importance\n",
    "\n",
    "### Task 8: Visualize feature importance\n",
    "For the Decision Tree model, visualize the importance of each feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8726c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Plot feature importance\n",
    "feature_names = X_train.columns\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(feature_names)), tree_model.feature_importances_, align='center')\n",
    "plt.yticks(np.arange(len(feature_names)), feature_names)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance in Decision Tree')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f447a8",
   "metadata": {},
   "source": [
    "## 7. Challenge: Implement XGBoost\n",
    "\n",
    "### Task 9: Train and evaluate an XGBoost model\n",
    "A suggestion is to implement an XGBoost model. Train the model and evaluate its performance just as you did with the previous models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your XGBoost code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfebd95-7cef-4d93-bd95-8f24170ea38d",
   "metadata": {},
   "source": [
    "# 8. Next Steps: Enrich your prediction with external data\n",
    "\n",
    "You could potentially improve your model by incorporating additional datasets.\n",
    "For example, if you're predicting river flow, you might want to look at:\n",
    "- **Weather data**: Rainfall, temperature, humidity, etc.\n",
    "    - Sources: OpenWeatherMap (API), NOAA Climate Data (https://www.ncdc.noaa.gov/cdo-web/), ECMWF (European Centre for Medium-Range Weather Forecasts)\n",
    "- **Geographical data**: Elevation, land use, soil moisture.\n",
    "    - Sources: USGS Earth Explorer (https://earthexplorer.usgs.gov/), NASA's Earth Data (https://earthdata.nasa.gov/)\n",
    "- **Hydrological data**: River discharge, water levels.\n",
    "    - Sources: Global Runoff Data Centre (https://www.bafg.de/GRDC/EN/Home/homepage_node.html), USGS Water Data (https://waterdata.usgs.gov/nwis)\n",
    "\n",
    "Think about what external factors could affect the target variable you're trying to predict.\n",
    "After you find a relevant dataset, consider how you can integrate it into your model.\n",
    "- Could you merge the data on a common time index?\n",
    "- Would this new data provide useful features (e.g., rainfall impacting river levels)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d67db0",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "Summarize your findings and reflect on the model performance:\n",
    "- Which model performed the best?\n",
    "- How important were the features in making predictions?\n",
    "- What feature engineering steps made the biggest difference?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
