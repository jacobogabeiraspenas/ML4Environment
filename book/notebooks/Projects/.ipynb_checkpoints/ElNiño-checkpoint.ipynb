{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae790c8-aa0f-44c7-8db3-9899619bb017",
   "metadata": {},
   "source": [
    "## Project: Forecast of El Nino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3923e740-9299-4bd2-b237-4c3293fcc79f",
   "metadata": {},
   "source": [
    "1. **Understand El Niño:**\n",
    "   - Begin by reading about El Niño to gain a deep understanding of what it is, how it affects the Pacific equatorial ocean, and its impact on the local economy. This foundational knowledge will help you make informed decisions about feature selection and model building.\n",
    "   \n",
    "   ![Weather Data](../images/monthly-sst-lanina-normal-elnino.png)\n",
    "\n",
    "2. **Data Exploration:**\n",
    "   - Start by exploring the provided dataset, which includes monthly sea surface temperature (SST) data. Understand the structure of the data, the temporal and spatial resolutions, and any additional variables if available.\n",
    "\n",
    "3. **Characterize El Niño:**\n",
    "   - Define and create a classifier variable that represents El Niño events in the dataset. El Niño is typically associated with higher sea surface temperatures in the tropical Pacific Ocean. You can use historical data and domain knowledge to label time periods as either \"El Niño\" or \"Non-El Niño\" based on specific criteria, such as SST thresholds.\n",
    "\n",
    "4. **Data Preprocessing:**\n",
    "   - Prepare the dataset for machine learning by cleaning, transforming, and encoding the data. Ensure that the dataset is in a format suitable for classification, with features and a target variable (El Niño classifier).\n",
    "\n",
    "5. **Feature Engineering:**\n",
    "   - Select relevant features that may influence El Niño events. These features could include sea surface temperatures, ocean current patterns, atmospheric pressure, and other climatic variables. You may also consider lagged variables, seasonal patterns, and spatial features.\n",
    "\n",
    "6. **Model Selection:**\n",
    "   - Choose an appropriate machine learning algorithm for classification. Common classifiers for binary classification tasks like this one include Logistic Regression, Random Forest, Support Vector Machine (SVM), Gradient Boosting, and Neural Networks.\n",
    "   - Experiment with different algorithms and hyperparameters to find the one that provides the best predictive performance.\n",
    "\n",
    "7. **Train and Validate the Model:**\n",
    "   - Split the dataset into training and validation sets to assess the model's performance. You can use techniques like cross-validation to evaluate model accuracy, precision, recall, and F1-score.\n",
    "\n",
    "8. **Model Interpretation:**\n",
    "   - Interpret the model's results to understand which features are most influential in predicting El Niño events. This insight can provide valuable information about the drivers of El Niño and its predictability.\n",
    "\n",
    "9. **Predict El Niño Events:**\n",
    "   - Once your model is trained and validated, you can use it to predict El Niño events for future time periods. Input the relevant features, and the model will output a prediction of whether El Niño is likely to occur.\n",
    "\n",
    "10. **Evaluate Predictability:**\n",
    "    - Assess the predictability of El Niño based on the model's performance. Calculate relevant evaluation metrics and consider the model's accuracy in predicting El Niño events.\n",
    "\n",
    "11. **Continuous Improvement:**\n",
    "    - Continue to refine and improve your model based on new data and insights. Monitoring and updating the model is essential for maintaining its predictive accuracy.\n",
    "\n",
    "In summary, building a machine learning model to predict El Niño involves data exploration, feature engineering, model selection, and evaluation. Additionally, understanding the implications of El Niño on the local economy and the predictability of El Niño events is crucial for building a relevant and impactful predictive model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1373380f-b88c-4531-a4a3-d483d730fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffc6f07c-6568-4df1-833b-93137e807f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 14:41:41,167 INFO Welcome to the CDS\n",
      "2023-11-16 14:41:41,168 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-11-16 14:41:41,233 INFO Request is queued\n",
      "2023-11-16 14:45:59,324 INFO Request is failed\n",
      "2023-11-16 14:45:59,332 ERROR Message: the request you have submitted is not valid\n",
      "2023-11-16 14:45:59,334 ERROR Reason:  None of the data you have requested is available yet, please revise the period requested. The latest date available for this dataset is: 2023-11-11 13:00\n",
      "2023-11-16 14:45:59,335 ERROR   Traceback (most recent call last):\n",
      "2023-11-16 14:45:59,336 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/cdshandlers/services/handler.py\", line 59, in handle_request\n",
      "2023-11-16 14:45:59,337 ERROR       result = cached(context.method, proc, context, context.args, context.kwargs)\n",
      "2023-11-16 14:45:59,338 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/caching.py\", line 108, in cached\n",
      "2023-11-16 14:45:59,339 ERROR       result = proc(context, *context.args, **context.kwargs)\n",
      "2023-11-16 14:45:59,340 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 124, in __call__\n",
      "2023-11-16 14:45:59,341 ERROR       return p(*args, **kwargs)\n",
      "2023-11-16 14:45:59,342 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 60, in __call__\n",
      "2023-11-16 14:45:59,343 ERROR       return self.proc(context, *args, **kwargs)\n",
      "2023-11-16 14:45:59,344 ERROR     File \"/home/cds/cdsservices/services/mars/mars.py\", line 48, in internal\n",
      "2023-11-16 14:45:59,345 ERROR       return mars(context, request, **kwargs)\n",
      "2023-11-16 14:45:59,346 ERROR     File \"/home/cds/cdsservices/services/mars/mars.py\", line 18, in mars\n",
      "2023-11-16 14:45:59,348 ERROR       **kwargs)\n",
      "2023-11-16 14:45:59,349 ERROR     File \"/home/cds/cdsservices/services/mars/preprocess_request.py\", line 37, in preprocess_request\n",
      "2023-11-16 14:45:59,350 ERROR       requests, fullconfig.get('embargo'), cacheable\n",
      "2023-11-16 14:45:59,351 ERROR     File \"/home/cds/cdsservices/services/mars/preprocess_request.py\", line 172, in implement_embargo\n",
      "2023-11-16 14:45:59,352 ERROR       f\"{embargo_datetime.strftime(embargo_error_time_format)}\", \"\"\n",
      "2023-11-16 14:45:59,352 ERROR   cdsinf.exceptions.BadRequestException: None of the data you have requested is available yet, please revise the period requested. The latest date available for this dataset is: 2023-11-11 13:00\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "the request you have submitted is not valid. None of the data you have requested is available yet, please revise the period requested. The latest date available for this dataset is: 2023-11-11 13:00.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m request \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreanalysis\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetcdf\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m13\u001b[39m)),  \u001b[38;5;66;03m# Request data for all months (1 to 12)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Make the API request and download the data\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreanalysis-era5-single-levels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdownload.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Close the API session\u001b[39;00m\n\u001b[1;32m     23\u001b[0m c\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/repre/lib/python3.9/site-packages/cdsapi/api.py:364\u001b[0m, in \u001b[0;36mClient.retrieve\u001b[0;34m(self, name, request, target)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, request, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 364\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m/resources/\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    366\u001b[0m         result\u001b[38;5;241m.\u001b[39mdownload(target)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/repre/lib/python3.9/site-packages/cdsapi/api.py:519\u001b[0m, in \u001b[0;36mClient._api\u001b[0;34m(self, url, request, method)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    518\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, n)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    520\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;241m%\u001b[39m (reply[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m), reply[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreason\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown API state [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (reply[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m],))\n",
      "\u001b[0;31mException\u001b[0m: the request you have submitted is not valid. None of the data you have requested is available yet, please revise the period requested. The latest date available for this dataset is: 2023-11-11 13:00."
     ]
    }
   ],
   "source": [
    "import cdsapi\n",
    "\n",
    "# Define your CDS API key\n",
    "api_key = '3604f1db-162d-4647-9b6b-d4f1af8fb039'\n",
    "\n",
    "# Create a CDS API client session\n",
    "c = cdsapi.Client()\n",
    "\n",
    "# Specify the dataset and request parameters\n",
    "request = {\n",
    "    'product_type': 'reanalysis',\n",
    "    'format': 'netcdf',\n",
    "    'variable': 'sea_surface_temperature',\n",
    "    'area': [-20, -100, 20, 80],  # [latitude_north, longitude_west, latitude_south, longitude_east]\n",
    "    'year': list(range(1990, 2024)),  # Request data from 1990 to the current year\n",
    "    'month': list(range(1, 13)),  # Request data for all months (1 to 12)\n",
    "}\n",
    "\n",
    "# Make the API request and download the data\n",
    "c.retrieve('reanalysis-era5-single-levels', request, 'download.nc')\n",
    "\n",
    "# Close the API session\n",
    "c.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f002b3-16d1-496a-884e-86b08e2f177e",
   "metadata": {},
   "source": [
    "## Model (Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e09c4-f854-4a58-9a4f-59a93aecec96",
   "metadata": {},
   "source": [
    "**Why Use a Neural Network (NN) for El Niño Prediction?**\n",
    "\n",
    "- **Complex SST Patterns:** El Niño events involve intricate sea surface temperature (SST) patterns. NNs are great at detecting these complex relationships.\n",
    "\n",
    "- **Automatic Feature Discovery:** NNs can find which SST features matter most for El Niño prediction, even when we're uncertain which ones are crucial.\n",
    "\n",
    "- **Non-Linear Relationships:** El Niño's behavior is not linear; it involves many factors interacting in non-obvious ways. NNs can capture these intricate, non-linear connections.\n",
    "\n",
    "- **Temporal and Spatial Data Handling:** NNs effectively process the temporal (time-based) and spatial (location-based) complexity in SST data, which is essential for predicting El Niño.\n",
    "\n",
    "- **Generalization:** Once trained on historical data, NNs can generalize to predict future El Niño events, learning from past SST patterns to make forecasts.\n",
    "\n",
    "- **Data Integration:** NNs can seamlessly integrate various data sources, like atmospheric and oceanic data, enhancing El Niño predictions with multi-modal information.\n",
    "\n",
    "In summary, NNs excel at untangling complex SST patterns, discovering important features, and handling non-linear relationships, making them a powerful tool for predicting El Niño events with precision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd75182-6cbf-4cba-9c37-83cb8a5a82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your SST data and labels (1 for El Niño, 0 for non-El Niño)\n",
    "# Replace 'X' and 'y' with your data and labels\n",
    "X = ...  # SST data in the shape (samples, 40, 180)\n",
    "y = ...  # Labels (1 for El Niño, 0 for non-El Niño)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the neural network model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(40, 180)),  # Flatten the input grid\n",
    "    keras.layers.Dense(128, activation='relu'),   # Fully connected layer with 128 units and ReLU activation\n",
    "    keras.layers.Dense(1, activation='sigmoid')   # Output layer with 1 unit and sigmoid activation (binary classification)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Binary cross-entropy loss for binary classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n"
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a CDS API Key\n",
    "To access data from the Copernicus Climate Data Store, you'll need an API key. You can obtain one by registering on the CDS website ([CDS Website](https://cds.climate.copernicus.eu/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the cdsapi Library\n",
    "Ensure you have the cdsapi Python library installed. You can install it using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cdsapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the cdsapi Library\n",
    "Import the cdsapi library at the beginning of your Python script or Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your CDS API Key\n",
    "Set your API key obtained from the CDS website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '3604f1db-162d-4647-9b6b-d4f1af8fb039'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a CDS API Client Session\n",
    "Initialize a client session with the CDS API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cdsapi.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Request Parameters\n",
    "Define the dataset you want to retrieve and specify the request parameters. In your example, you are requesting sea surface temperature (SST) data over a specific geographic area, time range, and data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {\n",
    "    'product_type': 'reanalysis',\n",
    "    'format': 'netcdf',\n",
    "    'variable': 'sea_surface_temperature',\n",
    "    'area': [-20, -100, 20, 80],  # [latitude_north, longitude_west, latitude_south, longitude_east]\n",
    "    'year': list(range(1990, 2024)),  # Request data from 1990 to the current year\n",
    "    'month': list(range(1, 13)),  # Request data for all months (1 to 12)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the API Request and Download Data\n",
    "Use the c.retrieve method to send the request to the CDS API and download the data. In your example, it retrieves ERA5 reanalysis data for sea surface temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.retrieve('reanalysis-era5-single-levels', request, 'download.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line of code will download the data in NetCDF format and save it as 'download.nc' in your current working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close the API Session\n",
    "After retrieving the data, it's good practice to close the API session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These steps outline how to use the cdsapi library to access and download climate data from the Copernicus Climate Data Store. Remember to replace the example API key with your actual API key obtained from the CDS website."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
