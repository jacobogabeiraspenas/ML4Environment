{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d334d0e1-6da5-4e70-b4cd-2ee30e359092",
   "metadata": {},
   "source": [
    "# Tutorial: Ensemble Methods for Wind Capacity Factor Prediction\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.in2p3.fr%2Fenergy4climate%2Fpublic%2Feducation%2Fmachine_learning_for_climate_and_energy/master?filepath=book%2Fnotebooks%2F08_tutorial_ensemble_methods_windcf_prediction.ipynb)\n",
    "\n",
    "Tutorial to the class [Ensemble Methods](08_ensemble_methods.ipynb) based on the same case study as in [Tutorial: Regularization, Model Selection and Evaluation](05_tutorial_regularization_selection_evaluation.ipynb) and [Tutorial: Introduction to Unsupervised Learning with a Focus on PCA](08_tutorial_unsupervised_learning_pca.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3af824-5f9e-44cc-b0d0-6a6b16f34bf8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Tutorial Objectives</b>\n",
    "    \n",
    "- Use ensemble methods to best predict the France-average wind capacity factor from a large number of input variables;\n",
    "- Control the complexity parameter(s) of each ensemble method to avoid overfitting;\n",
    "- Compare the skills of different methods.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d9366-41c2-4ce2-b5d1-ecc291a6fe31",
   "metadata": {},
   "source": [
    "## Scientific objective\n",
    "\n",
    "To predict the France average wind capacity factor from the geopotential height at 500hPa over the Euro-Atlantic sector.\n",
    "\n",
    "## Dataset presentation\n",
    "\n",
    "- Input:\n",
    "  - [Geopotential height](https://en.wikipedia.org/wiki/Geopotential_height) at 500hPa\n",
    "    - Domain: North Atlantic\n",
    "    - Spatial resolution: $0.5° \\times 0.625°$\n",
    "    - Time resolution: monthly\n",
    "    - Period: 1980-2021\n",
    "    - Units: m\n",
    "    - Source: [MERRA-2 reanalysis](https://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/)\n",
    "- Target:\n",
    "  - Onshore wind capacity factors\n",
    "    - Domain: Metropolitan France\n",
    "    - Spatial resolution: regional mean\n",
    "    - Time resolution: daily\n",
    "    - Period: 2014-2021\n",
    "    - Units:\n",
    "    - Source: [RTE](https://opendata.reseaux-energies.fr/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37dc9ce-7ae8-42b8-b053-0a8d310280fe",
   "metadata": {},
   "source": [
    "## Getting ready\n",
    "\n",
    "### Reading the wind capacity factor and geopotential height data\n",
    "\n",
    "We follow the same procedure as in [# Tutorial: Regularization, Model Selection and Evaluation](05_tutorial_regularization_selection_evaluation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06807ec3-bd04-4696-bd36-b7a742425148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path manipulation module\n",
    "from pathlib import Path\n",
    "# Numerical analysis module\n",
    "import numpy as np\n",
    "# Formatted numerical analysis module\n",
    "import pandas as pd\n",
    "# Structured dataset analysis module\n",
    "import xarray as xr\n",
    "# Plot module\n",
    "import matplotlib.pyplot as plt\n",
    "# Default colors\n",
    "RC_COLORS = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "# Matplotlib configuration\n",
    "plt.rc('font', size=14)\n",
    "\n",
    "# Set data directory\n",
    "data_dir = Path('data')\n",
    "\n",
    "# Set keyword arguments for pd.read_csv\n",
    "kwargs_read_csv = dict(index_col=0, parse_dates=True) \n",
    "\n",
    "# Define electricity demand filepath and label\n",
    "windcf_filename = 'reseaux_energies_capacityfactor_wind-onshore.csv'\n",
    "windcf_filepath = Path(data_dir, windcf_filename)\n",
    "windcf_label = 'Wind capacity factor'\n",
    "\n",
    "# Read windcf data with pandas                                                                                                                                                \n",
    "df_windcf_daily = pd.read_csv(windcf_filepath, **kwargs_read_csv)\n",
    "\n",
    "# Select domain\n",
    "# REGION_NAME = 'Bretagne'\n",
    "REGION_NAME = 'National'\n",
    "if REGION_NAME == 'National':\n",
    "    df_windcf_daily_reg = df_windcf_daily.mean('columns')\n",
    "    df_windcf_daily_reg.name = REGION_NAME\n",
    "else:\n",
    "    df_windcf_daily_reg = df_windcf_daily[REGION_NAME]\n",
    "\n",
    "# Resample wind capacity factor from daily to monthly means\n",
    "df_windcf_reg = df_windcf_daily_reg.resample('MS').mean()\n",
    "\n",
    "# Define temperature filepath and label\n",
    "START_DATE = '19800101'\n",
    "END_DATE = '20220101'\n",
    "z500_filename = 'merra2_analyze_height_500_month_{}-{}.nc'.format(START_DATE, END_DATE)\n",
    "z500_filepath = Path(data_dir, z500_filename)\n",
    "z500_label = 'Geopotential height (m)'\n",
    "\n",
    "# Read geopotential height dataset with xarray                                                                                                                                \n",
    "ds = xr.load_dataset(z500_filepath)\n",
    "\n",
    "# Select geopotential height variable                                                                                                                                         \n",
    "z500_name = 'height_500'                                                                                                                                                     \n",
    "da_z500_hr = ds[z500_name]\n",
    "\n",
    "# Downsample geopotential height\n",
    "N_GRID_AVG = 8\n",
    "da_z500 = da_z500_hr.coarsen(lat=N_GRID_AVG, boundary='trim').mean().coarsen(                                                                                                 \n",
    "    lon=N_GRID_AVG, boundary='trim').mean()\n",
    "\n",
    "# Remove seasonal cycle from wind capacity factor\n",
    "da_windcf_reg = df_windcf_reg.to_xarray()                                                                                                                                 \n",
    "gp_windcf_cycle = da_windcf_reg.groupby('time.month')                                                                                                                     \n",
    "da_windcf_anom = gp_windcf_cycle - gp_windcf_cycle.mean('time')                                                                                                           \n",
    "df_windcf_anom = da_windcf_anom.drop('month').to_dataframe()[REGION_NAME]\n",
    "\n",
    "# Remove seasonal cycle from geopotential height or not\n",
    "gp_z500_cycle = da_z500.groupby('time.month')                                                                                                                             \n",
    "da_z500_anom = gp_z500_cycle - gp_z500_cycle.mean('time')\n",
    "\n",
    "# Convert to bandas with grid points as columns                                                                                                                               \n",
    "df_z500_anom = da_z500_anom.stack(latlon=('lat', 'lon')).to_dataframe()[\n",
    "    z500_name].unstack(0).transpose()\n",
    "    \n",
    "# Select common index                                                                                                                                                         \n",
    "idx = df_z500_anom.index.intersection(df_windcf_anom.index)                                                                                                                   \n",
    "df_z500_anom = df_z500_anom.loc[idx]                                                                                                                                          \n",
    "df_windcf_anom = df_windcf_anom.loc[idx]                                                                                                                                      \n",
    "                                                                                                                                                                              \n",
    "# Number of years in dataset                                                                                                                                                  \n",
    "time = df_windcf_anom.index                                                                                                                                                   \n",
    "n_years = time.year.max() - time.year.min() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eb8536-db40-4080-bace-dc0f6ae7b468",
   "metadata": {},
   "source": [
    "## Ensemble methods\n",
    "\n",
    "### Regressions evaluation function\n",
    "\n",
    "We also define a function to evaluate any of our regressions.\n",
    "\n",
    "`FIRST_TEST_YEAR` controls the number of years at the end of the time series to keep as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3090f6bd-b880-45db-83cf-7dd3b4a9316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# Default number of test days\n",
    "FIRST_TEST_YEAR = 2020\n",
    "\n",
    "POLY_DEGREE = 1\n",
    "\n",
    "# Get input matrix and output vector for whole time series\n",
    "X = df_z500_anom.values\n",
    "y = df_windcf_anom.values\n",
    "\n",
    "def evaluate_regressor(\n",
    "    reg, reg_kwargs, param_name, param_range, first_test_year=FIRST_TEST_YEAR,\n",
    "    n_splits=None, cv_iterator=model_selection.KFold,\n",
    "    plot_validation=True):\n",
    "    \n",
    "    if n_splits is None:\n",
    "        n_splits = len(np.unique(time[time.year < first_test_year].year))\n",
    "    \n",
    "    # Get test data keeping last years\n",
    "    index_test = time.year >= first_test_year\n",
    "    X_test = X[index_test]\n",
    "    y_test = y[index_test]\n",
    "    \n",
    "    # Select train data from first years and first days in month \n",
    "    index_cv = time.year < first_test_year\n",
    "    X_cv = X[index_cv]\n",
    "    y_cv = y[index_cv]\n",
    "    \n",
    "    if plot_validation:\n",
    "        # Set cross-validation iterator\n",
    "        cv = cv_iterator(n_splits=n_splits)\n",
    "        groups = time[index_cv].year\n",
    "\n",
    "        # Get train and validation scores from cross-validation\n",
    "        train_scores, validation_scores = model_selection.validation_curve(\n",
    "            reg, X_cv, y_cv, param_name=param_name,\n",
    "            param_range=param_range, cv=cv, groups=groups)\n",
    "\n",
    "        # Get train curve\n",
    "        train_scores_mean = train_scores.mean(1)\n",
    "        train_scores_max = train_scores.max(1)\n",
    "        train_scores_min = train_scores.min(1)\n",
    "\n",
    "        # Get validation curve\n",
    "        validation_scores_mean = validation_scores.mean(1)\n",
    "        validation_scores_max = validation_scores.max(1)\n",
    "        validation_scores_min = validation_scores.min(1)\n",
    "\n",
    "        # Get best value of the regularization parameter\n",
    "        i_best = np.argmax(validation_scores_mean)\n",
    "        param_best = param_range[i_best]\n",
    "        score_best = validation_scores_mean[i_best]\n",
    "\n",
    "    \n",
    "        # Plot validation curve\n",
    "        lw = 2\n",
    "        plt.figure()\n",
    "        plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "        plt.fill_between(param_range, train_scores_min, train_scores_max,\n",
    "                         alpha=0.2, color=\"darkorange\", lw=lw)\n",
    "        plt.semilogx(param_range, validation_scores_mean,\n",
    "                     label=\"Cross-validation score\", color=\"navy\", lw=lw)\n",
    "        plt.fill_between(\n",
    "            param_range, validation_scores_min, validation_scores_max,\n",
    "            alpha=0.2, color=\"navy\", lw=lw)\n",
    "        plt.xlabel(param_name)\n",
    "        plt.ylabel(r'Validation $R^2$')\n",
    "        plt.xlim(param_range[[0, -1]])\n",
    "        plt.title(REGION_NAME + r'. Best $R^2$: {:.2} for {} = {:.1e}'.format(\n",
    "            score_best, param_name, param_best))\n",
    "        # plt.ylim(0.0, 1.1)\n",
    "        plt.legend(loc=\"best\")\n",
    "        \n",
    "        # Set best parameter\n",
    "        reg.set_params(**{param_name: param_best})\n",
    "    else:\n",
    "        param_best = reg.get_params(param_name)\n",
    "        \n",
    "    # Compute prediction error conditioned on first 5 years of data\n",
    "    reg.fit(X_cv, y_cv)\n",
    "    test_score = reg.score(X_test, y_test)\n",
    "    print('\\nTest R2: {:.2f}'.format(test_score))\n",
    "\n",
    "    # Predict for work days and off days\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    # Scatter plot of prediction against target\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(y_test, y_pred, s=10, alpha=0.5)\n",
    "    xlim = ax.get_xlim()\n",
    "    ax.plot(xlim, xlim, '--k', linewidth=1)\n",
    "    ax.set_xlabel('Target ' + windcf_label)\n",
    "    ax.set_ylabel('Predicted ' + windcf_label)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_title('Wind capacity factor')\n",
    "    \n",
    "    return {param_name: param_best}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f510488-6309-4774-9df8-dbaa77586e53",
   "metadata": {},
   "source": [
    "> ***Question***\n",
    "> - If 2021 is given as the first test years, how many training years and test years will be available for this dataset?\n",
    "> - Identify the lines where:\n",
    ">   - The validation and train scores are computed;\n",
    ">   - The test score is computed;\n",
    ">   - The target is predicted from the test input features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dc1c00-31a0-4daa-91d3-9b755ea96f56",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721cdb82-c106-4cf7-8c4a-12668b032dc5",
   "metadata": {},
   "source": [
    "## Individual models\n",
    "\n",
    "First, make sure that only the heating and cooling temperatures are selected as features, that the monthly factorization is activated and that no polynomial transformation is performed.\n",
    "\n",
    "### Lasso regression\n",
    "\n",
    "The following code:\n",
    "- Creates a Lasso regressor with positive coefficients;\n",
    "- Evaluate the regressor over a range of regularization parameter values;\n",
    "- Represent the importance of the coefficients.\n",
    "\n",
    "The evaluation function:\n",
    "- Plots the training and validation curves with the lines representing the mean score and the shading the minimum and maximum scores;\n",
    "- Plots test predictions against the test inputs over the train data;\n",
    "- Plots the test predictions against the test targets.\n",
    "\n",
    "> ***Question***\n",
    "> - Is there an overfit/underfit tradeoff?\n",
    "> - Explain the difference between the training curve and the validation curve?\n",
    "> - Explain the evolution the variability of the validation curve.\n",
    "> - Is the test score in agreement with the best validation score?\n",
    "> - How does the the importance of the coefficients vary with climate variable and the month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5887f22f-bd23-4e1a-a35a-0be7a307154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Define array of complexity coordinate, regressor and options\n",
    "# for Lasso regression\n",
    "param_name, param_range = 'alpha', np.logspace(-4, 1, 50)\n",
    "reg_kwargs_lasso = dict(max_iter=10000)\n",
    "reg_lasso = linear_model.Lasso(\n",
    "    **{param_name: param_range[0]}, **reg_kwargs_lasso)\n",
    "\n",
    "# Evaluate regressor\n",
    "param_best_lasso = evaluate_regressor(\n",
    "    reg_lasso, reg_kwargs_lasso, param_name, param_range)\n",
    "df_coef = pd.Series(reg_lasso.coef_)\n",
    "plt.figure()\n",
    "df_coef.plot(kind='barh', figsize=(8, 8))\n",
    "plt.xlabel(r'Coefficient value (m$^{-1}$)')\n",
    "plt.ylabel('Grid point')\n",
    "_ = plt.title('Model coefficients')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168b8f3b-d12f-49b9-89cf-d6b994d3a092",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4313de1c-c8fc-4525-b302-614cd033f0fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decision-tree regression\n",
    "\n",
    "The following code:\n",
    "- Creates a decision-tree regressor;\n",
    "- Evaluate the regressor over a range of maximum tree depth;\n",
    "\n",
    "> ***Question***\n",
    "> - Is there an overfit/underfit tradeoff?\n",
    "> - How does the tree perform compared to the Lasso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0909313b-d62a-4708-a667-e5669ce020f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# Define array of complexity coordinate, regressor and options\n",
    "# for decision-tree regression\n",
    "param_name, param_range = 'max_depth', np.arange(1, 20, 1)\n",
    "reg_kwargs_dt = dict()\n",
    "reg_dt = tree.DecisionTreeRegressor(\n",
    "    **{param_name: param_range[0]}, **reg_kwargs_dt)\n",
    "\n",
    "# Evaluate regressor\n",
    "param_best_dt = evaluate_regressor(\n",
    "    reg_dt, reg_kwargs_dt, param_name, param_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b1c87e-7c84-4d68-bc22-d4f7b09d7841",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c81942-d15f-4ad0-b69c-b1d8a8c0eb6c",
   "metadata": {},
   "source": [
    "## Ensemble models\n",
    "\n",
    "### Bagging regressor\n",
    "\n",
    "The following code:\n",
    "- Creates a bagging regressor with a decision tree as the base estimator;\n",
    "- Evaluate the regressor over a range of number of estimators;\n",
    "\n",
    "> ***Question***\n",
    "> - Use the Scikit-learn documentation to give the parameters defining this bagging regressor with a decision tree as the base estimator.\n",
    "\n",
    "> ***Question***\n",
    "> - Is there an overfit/underfit tradeoff?\n",
    "> - In this case, how to choose the number of estimators?\n",
    "> - Same question without using validation curves.\n",
    "> - How does the bagging perform compared to the individual regressors?\n",
    "> - Same question but with the Lasso as base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e061aa0b-3156-4eba-94d2-2ed722f93f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "# Define array of complexity coordinate, regressor and options\n",
    "# for Bagging regression\n",
    "param_name, param_range = 'n_estimators', np.arange(1, 50, 2)\n",
    "# base_estimator = None\n",
    "base_estimator = linear_model.Lasso(alpha=0.15)\n",
    "reg_kwargs_br = dict(base_estimator=base_estimator)\n",
    "reg_br = ensemble.BaggingRegressor(\n",
    "    **{param_name: param_range[0]}, **reg_kwargs_br)\n",
    "\n",
    "# Evaluate regressor\n",
    "param_best_br = evaluate_regressor(\n",
    "    reg_br, reg_kwargs_br, param_name, param_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c63c9-0708-4a0d-9e5b-d41e792f5eeb",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0359d5-0bce-4ab4-9e22-7fe0c35b1718",
   "metadata": {},
   "source": [
    "### Random-forest regressor\n",
    "\n",
    "The following code:\n",
    "- Creates a random-forest regressor;\n",
    "- Evaluate the regressor over a range of number of estimators;\n",
    "\n",
    "> ***Question***\n",
    "> - Use the Scikit-learn documentation to give the parameters defining this random-forest regressor.\n",
    "\n",
    "> ***Question***\n",
    "> - How does the random forest perform compared to the bagging regressor?\n",
    "> - Compare the varibility of the validation score of the random forest to that of the bagging regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfca96a-7de8-4b3b-a361-1b533dc5ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define array of complexity coordinate, regressor and options\n",
    "# for random-forest regression\n",
    "param_name, param_range = 'n_estimators', np.arange(1, 202, 25)\n",
    "reg_kwargs_rf = dict()\n",
    "reg_rf = ensemble.RandomForestRegressor(\n",
    "    **{param_name: param_range[0]}, **reg_kwargs_rf)\n",
    "\n",
    "# Evaluate regressor\n",
    "param_best_rf = evaluate_regressor(\n",
    "    reg_rf, reg_kwargs_rf, param_name, param_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9965433-f902-469b-af93-22a02ca6a86e",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e79e3b-9ea7-4a9d-999f-a88a05a74536",
   "metadata": {},
   "source": [
    "The following plot represents the mean and standard deviation of the importance given to the features by the trees in the random forest (see [Feature importance with a forest of trees in Scikit-learn User guide](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html#feature-importances-with-a-forest-of-trees)).\n",
    "\n",
    "> ***Question***\n",
    "> - How does the the importance of the features vary with climate variable and the month?\n",
    "> - Compare the importance of the random-forest features with that of the Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e507a17-b985-411d-a09c-abacafed67e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot importance\n",
    "importances = reg_rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in reg_rf.estimators_], axis=0)\n",
    "forest_importances = pd.Series(importances)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "_ = ax.set_ylabel(\"Mean decrease in impurity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbdf543-da00-49a9-b393-76c088c6cc4e",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c12d10a-222b-4003-88e0-c2957bf5e822",
   "metadata": {},
   "source": [
    "### Voting regressor\n",
    "\n",
    "The following code creates a voting regressor with the Lasso, the decision tree and the random forest as base estimators and tests it.\n",
    "\n",
    "> ***Question***\n",
    "> - Use the Scikit-learn documentation to give the parameters defining this voting regressor.\n",
    "\n",
    "> ***Question***\n",
    "> - How does the voting regressor perform compared to the base estimators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15a9af-0391-42ae-914b-188ebcfc7d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define array of complexity coordinate, regressor and options\n",
    "# for voting regression\n",
    "param_name, param_range = 'estimators', [\n",
    "    [('Lasso', reg_lasso), ('DecisionTree', reg_dt), ('RandomForest', reg_rf)]\n",
    "]\n",
    "reg_kwargs_vr = dict()\n",
    "reg_vr = ensemble.VotingRegressor(\n",
    "    **{param_name: param_range[0]}, **reg_kwargs_vr)\n",
    "\n",
    "# Evaluate regressor\n",
    "param_best_vr = evaluate_regressor(\n",
    "    reg_vr, reg_kwargs_vr, param_name, param_range,\n",
    "    plot_validation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f215f7dd-e79a-47b2-9131-2436eb80daa3",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7edfbb-fb38-472b-9cb9-e5c103482517",
   "metadata": {},
   "source": [
    "### Stacking regressor\n",
    "\n",
    "- The following code creates a stacking regressor with the Lasso, the decision tree and the random forest as base estimators and tests it.\n",
    "- The final regressor is a OLS with positive coefficients.\n",
    "- The weights given to the base estimators by the stacking are also given.\n",
    "\n",
    "> ***Question***\n",
    "> - Use the Scikit-learn documentation to give the parameters defining this stacking regressor.\n",
    "\n",
    "> ***Question***\n",
    "> - How does the stacking regressor perform compared to the voting regressor? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839d2a15-179c-4d18-bd36-1c8646b8061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define array of complexity coordinate, regressor and options\n",
    "# for voting regression\n",
    "param_name, param_range = 'estimators', [\n",
    "    [('Lasso', reg_lasso), ('DecisionTree', reg_dt), ('RandomForest', reg_rf)]\n",
    "]\n",
    "reg_kwargs_sr = dict(final_estimator=linear_model.LinearRegression(\n",
    "    positive=True))\n",
    "reg_sr = ensemble.StackingRegressor(\n",
    "    **{param_name: param_range[0]}, **reg_kwargs_sr)\n",
    "\n",
    "# Evaluate regressor\n",
    "param_best_sr = evaluate_regressor(\n",
    "    reg_sr, reg_kwargs_sr, param_name, param_range, plot_validation=False)\n",
    "weights = reg_sr.final_estimator_.coef_\n",
    "index = [r[0] for r in param_range[0]]\n",
    "df_weights = pd.Series(weights, index=index)\n",
    "print('Weights:')\n",
    "print(df_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc13be1-32a3-4125-a509-9bc0f78832d1",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23469d46-5a6c-4d27-86b1-f19c5ec962d6",
   "metadata": {},
   "source": [
    "### AdaBoost regressor\n",
    "\n",
    "The following code:\n",
    "- Creates an AdaBoost regressor;\n",
    "- Evaluate the regressor over a range of number of estimators;\n",
    "\n",
    "> ***Question***\n",
    "> - Use the Scikit-learn documentation to give the parameters defining this AdaBoost regressor.\n",
    "\n",
    "> ***Question***\n",
    "> - How does the AdaBoost compared to the other regressors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af026c4-c890-4d2a-a78a-2593b4f1d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define array of complexity coordinate, regressor and options\n",
    "# for AdaBoost regression\n",
    "param_name, param_range = 'n_estimators', np.arange(1, 50, 2)\n",
    "base_estimator = linear_model.LinearRegression(fit_intercept=True)\n",
    "reg_kwargs_abr = dict(base_estimator=base_estimator)\n",
    "reg_abr = ensemble.AdaBoostRegressor(\n",
    "    **{param_name: param_range[0]}, **reg_kwargs_abr)\n",
    "\n",
    "# Evaluate regressor\n",
    "param_best_abr = evaluate_regressor(\n",
    "    reg_abr, reg_kwargs_abr, param_name, param_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeddb75-38c2-45a6-8061-8441662a193c",
   "metadata": {},
   "source": [
    "> ***Question (Optional)***\n",
    "> - Reevaluate your results for a different scoring metric.\n",
    "\n",
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cb0e4f-af28-4e1d-ae09-2f0f5c909707",
   "metadata": {},
   "source": [
    "***\n",
    "## Credit\n",
    "\n",
    "[//]: # \"This notebook is part of [E4C Interdisciplinary Center - Education](https://gitlab.in2p3.fr/energy4climate/public/education).\"\n",
    "Contributors include Bruno Deremble and Alexis Tantet.\n",
    "Several slides and images are taken from the very good [Scikit-learn course](https://inria.github.io/scikit-learn-mooc/).\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"display: flex; height: 70px\">\n",
    "    \n",
    "<img alt=\"Logo LMD\" src=\"images/logos/logo_lmd.jpg\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo IPSL\" src=\"images/logos/logo_ipsl.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo E4C\" src=\"images/logos/logo_e4c_final.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo EP\" src=\"images/logos/logo_ep.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo SU\" src=\"images/logos/logo_su.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo ENS\" src=\"images/logos/logo_ens.jpg\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo CNRS\" src=\"images/logos/logo_cnrs.png\" style=\"display: inline-block\"/>\n",
    "    \n",
    "</div>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<div style=\"display: flex\">\n",
    "    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0; margin-right: 10px\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a>\n",
    "    <br>This work is licensed under a &nbsp; <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
